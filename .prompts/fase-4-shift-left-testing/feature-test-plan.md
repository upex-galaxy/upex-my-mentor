Act√∫a como QA Lead experto en Shift-Left Testing, Test Strategy y Quality Analysis.

**Input (Contexto Completo Obligatorio):**

**Contexto de Negocio:**

- Business Model: [usar .context/idea/business-model.md]
- Executive Summary: [usar .context/PRD/executive-summary.md]
- User Personas: [usar .context/PRD/user-personas.md]
- User Journeys: [usar .context/PRD/user-journeys.md]

**Contexto T√©cnico:**

- Functional Specs: [usar .context/SRS/functional-specs.md - COMPLETO]
- Non-Functional Specs: [usar .context/SRS/non-functional-specs.md]
- Architecture Specs: [usar .context/SRS/architecture-specs.md]
- API Contracts: [usar .context/SRS/api-contracts.yaml]

**Contexto de la Feature:**

- Epic: [usar .context/PBI/epics/EPIC-{PROYECTO}-{NUM}-{nombre}/epic.md]
- Todas las stories de la √©pica: [leer todos los story.md de la √©pica]

**Genera archivo: feature-test-plan.md** (dentro de .context/PBI/epics/EPIC-{PROYECTO}-{NUM}-{nombre}/)

---

## üéØ FLUJO DE TRABAJO

Este prompt trabaja en 5 fases para entregar un plan de pruebas completo con an√°lisis cr√≠tico:

### FASE 1: An√°lisis de Contexto

- Entender el valor de negocio de la √©pica
- Identificar usuarios afectados
- Analizar arquitectura involucrada

### FASE 2: An√°lisis de Riesgos

- Identificar riesgos t√©cnicos
- Identificar riesgos de negocio
- Identificar puntos de integraci√≥n cr√≠ticos

### FASE 3: Estrategia de Testing

- Definir niveles de testing requeridos
- Definir tipos de testing por story
- Definir scope de testing

### FASE 4: An√°lisis Cr√≠tico

- Identificar ambig√ºedades en √©pica/stories
- Generar preguntas para PO/Dev
- Sugerir mejoras antes de implementaci√≥n

### FASE 5: Plan de Testing

- Entry/Exit criteria
- Test data requirements
- Estimaci√≥n de test cases por story

---

# Feature Test Plan: EPIC-{PROYECTO}-{NUM} - [Epic Title]

**Fecha:** [YYYY-MM-DD]
**QA Lead:** [Nombre o "TBD"]
**Epic Jira Key:** [EPIC-XXX]
**Status:** Draft | In Review | Approved

---

## üìã Business Context Analysis

### Business Value

[Explicar el valor de negocio de esta √©pica seg√∫n Business Model Canvas y Executive Summary]

**Key Value Proposition:**

- [Valor 1 que aporta al usuario]
- [Valor 2 que aporta al negocio]

**Success Metrics (KPIs):**

- [KPI 1 del Executive Summary que esta √©pica impacta]
- [KPI 2 del Executive Summary que esta √©pica impacta]

**User Impact:**
[Listar qu√© user personas son afectadas por esta √©pica]

- Persona 1: [Nombre] - [C√≥mo le afecta]
- Persona 2: [Nombre] - [C√≥mo le afecta]

**Critical User Journeys:**
[Listar user journeys del PRD que esta √©pica habilita o modifica]

- Journey 1: [Nombre]
- Journey 2: [Nombre]

---

## üèóÔ∏è Technical Architecture Analysis

### Architecture Components Involved

**Frontend:**

- [Componentes React/Vue a crear o modificar]
- [P√°ginas/rutas afectadas]

**Backend:**

- [APIs a crear o modificar - referenciar api-contracts.yaml]
- [Servicios de negocio afectados]

**Database:**

- [Tablas involucradas - referenciar architecture-specs.md]
- [Queries cr√≠ticos]

**External Services:**

- [APIs externas involucradas]
- [Third-party services (Stripe, email, etc.)]

### Integration Points (Critical for Testing)

[Basado en architecture-specs.md, identificar puntos de integraci√≥n]

**Internal Integration Points:**

- Frontend ‚Üî Backend API
- Backend ‚Üî Database
- Backend ‚Üî Auth Service
- [Otros m√≥dulos internos]

**External Integration Points:**

- [Sistema] ‚Üî [Servicio externo 1]
- [Sistema] ‚Üî [Servicio externo 2]

**Data Flow:**

```
[Describir flujo de datos cr√≠tico]
User ‚Üí Frontend ‚Üí API Gateway ‚Üí Service X ‚Üí Database
                              ‚Üì
                         External Service
```

---

## üö® Risk Analysis

### Technical Risks

#### Risk 1: [Descripci√≥n del riesgo t√©cnico]

- **Impact:** High | Medium | Low
- **Likelihood:** High | Medium | Low
- **Area Affected:** [Frontend | Backend | Database | Integration]
- **Mitigation Strategy:**
  - [Estrategia 1]
  - [Testing approach espec√≠fico]
- **Test Coverage Required:** [Qu√© test cases necesitamos para mitigar]

#### Risk 2: [Descripci√≥n del riesgo t√©cnico]

- **Impact:** ...
- **Likelihood:** ...
- **Area Affected:** ...
- **Mitigation Strategy:** ...
- **Test Coverage Required:** ...

---

### Business Risks

#### Risk 1: [Descripci√≥n del riesgo de negocio]

- **Impact on Business:** [C√≥mo afecta KPIs o user experience]
- **Impact on Users:** [Qu√© user personas se ven afectadas]
- **Likelihood:** High | Medium | Low
- **Mitigation Strategy:**
  - [Qu√© testing hacemos para prevenir]
  - [Qu√© validaciones de negocio agregamos]
- **Acceptance Criteria Validation:** [Validar que acceptance criteria cubran este riesgo]

#### Risk 2: [Descripci√≥n del riesgo de negocio]

- **Impact on Business:** ...
- **Impact on Users:** ...
- **Likelihood:** ...
- **Mitigation Strategy:** ...

---

### Integration Risks

[Identificar riesgos en puntos de integraci√≥n identificados anteriormente]

#### Integration Risk 1: [Descripci√≥n]

- **Integration Point:** [Frontend ‚Üî API | API ‚Üî Database | etc.]
- **What Could Go Wrong:** [Escenarios de falla]
- **Impact:** High | Medium | Low
- **Mitigation:**
  - Integration tests espec√≠ficos
  - Contract testing (si aplica)
  - Mocking strategy para testing aislado

---

## ‚ö†Ô∏è Critical Analysis & Questions for PO/Dev

### Ambiguities Identified

[Analizar epic.md y todos los story.md de la √©pica para identificar ambig√ºedades]

**Ambiguity 1:** [Descripci√≥n de la ambig√ºedad]

- **Found in:** STORY-{PROYECTO}-{NUM}
- **Question for PO:** [Pregunta espec√≠fica]
- **Impact if not clarified:** [Qu√© problemas puede causar]

**Ambiguity 2:** [Descripci√≥n]

- **Found in:** EPIC-{PROYECTO}-{NUM} scope
- **Question for Dev:** [Pregunta t√©cnica]
- **Impact if not clarified:** ...

---

### Missing Information

[Identificar qu√© informaci√≥n falta en epic.md o stories para poder testear correctamente]

**Missing 1:** [Qu√© falta]

- **Needed for:** [Por qu√© es cr√≠tico para testing]
- **Suggestion:** [Qu√© agregar a la story/epic]

**Missing 2:** [Qu√© falta]

- **Needed for:** ...
- **Suggestion:** ...

---

### Suggested Improvements (Before Implementation)

[Sugerencias para mejorar stories ANTES de que Dev empiece a implementar]

**Improvement 1:** [Sugerencia]

- **Story Affected:** STORY-{PROYECTO}-{NUM}
- **Current State:** [C√≥mo est√° ahora]
- **Suggested Change:** [C√≥mo deber√≠a estar]
- **Benefit:** [Por qu√© mejora la quality]

**Improvement 2:** [Sugerencia]

- **Story Affected:** ...
- **Current State:** ...
- **Suggested Change:** ...
- **Benefit:** ...

---

## üéØ Test Strategy

### Test Scope

**In Scope:**

- Functional testing (UI, API, Database)
- Integration testing (internal + external services)
- Non-functional testing (Performance, Security seg√∫n NFRs)
- Cross-browser testing (Chrome, Firefox, Safari)
- Mobile responsiveness (iOS Safari, Android Chrome)
- API contract validation (seg√∫n api-contracts.yaml)
- Data validation (input/output seg√∫n SRS)

**Out of Scope (For This Epic):**

- [Features que NO se testean en esta √©pica]
- [Testing que se deja para otras √©picas]
- [Testing que se contrata externo: penetration testing, load testing extremo, etc.]

---

### Test Levels

#### Unit Testing

- **Coverage Goal:** > 80% code coverage
- **Focus Areas:**
  - Business logic functions/methods
  - Data validation functions
  - Utility functions
- **Responsibility:** Dev team (pero QA valida que existan)

#### Integration Testing

- **Coverage Goal:** All integration points identified above
- **Focus Areas:**
  - Frontend ‚Üî Backend API (seg√∫n api-contracts.yaml)
  - Backend ‚Üî Database
  - Backend ‚Üî External Services (mocked)
- **Responsibility:** QA + Dev (pair programming)

#### End-to-End (E2E) Testing

- **Coverage Goal:** Critical user journeys completos
- **Tool:** Playwright
- **Focus Areas:**
  - [User Journey 1 identificado arriba]
  - [User Journey 2 identificado arriba]
  - Happy paths completos
  - Error scenarios cr√≠ticos
- **Responsibility:** QA team

#### API Testing

- **Coverage Goal:** 100% de endpoints de esta √©pica (seg√∫n api-contracts.yaml)
- **Tool:** Postman/Newman o Playwright API
- **Focus Areas:**
  - Contract validation (request/response seg√∫n OpenAPI spec)
  - Status codes correctos
  - Error handling
  - Authentication/Authorization
- **Responsibility:** QA team

---

### Test Types per Story

Por cada story de esta √©pica, se deben cubrir:

**Positive Test Cases:**

- Happy path (flujo exitoso)
- Valid data variations (diferentes datos v√°lidos)

**Negative Test Cases:**

- Invalid input data
- Missing required fields
- Unauthorized access attempts
- Boundary violations

**Boundary Test Cases:**

- Min/max values
- Empty/null values
- Edge cases espec√≠ficos del dominio

**Exploratory Testing:**

- [√Åreas que requieren exploratory testing - explicar por qu√©]
- Sugerencia: Hacer exploratory testing ANTES de implementaci√≥n (usando mockups/prototypes)

---

## üìä Test Cases Summary by Story

[Por cada story de la √©pica, estimar cu√°ntos test cases se necesitan - SIN forzar n√∫mero m√≠nimo]

### STORY-{PROYECTO}-{NUM}: [Story Title]

**Complexity:** Low | Medium | High
**Estimated Test Cases:** [N√∫mero realista - puede ser 1, puede ser 20]

- Positive: [X] test cases
- Negative: [Y] test cases
- Boundary: [Z] test cases
- Integration: [W] test cases (si aplica)
- API: [V] test cases (si aplica)

**Rationale for estimate:**
[Explicar por qu√© ese n√∫mero - complejidad, integration points, edge cases identificados]

**Parametrized Tests Recommended:** Yes | No
[Si Yes, explicar qu√© tests se benefician de parametrizaci√≥n]

---

### STORY-{PROYECTO}-{NUM}: [Story Title]

**Complexity:** ...
**Estimated Test Cases:** ...

- ...

**Rationale for estimate:** ...
**Parametrized Tests Recommended:** ...

---

[Repetir para todas las stories de la √©pica]

---

### Total Estimated Test Cases for Epic

**Total:** [Suma de todos los test cases estimados]
**Breakdown:**

- Positive: [X]
- Negative: [Y]
- Boundary: [Z]
- Integration: [W]
- API: [V]

---

## üóÇÔ∏è Test Data Requirements

### Test Data Strategy

**Valid Data Sets:**
[Basado en user personas y SRS, definir datos v√°lidos realistas]

- User data: [Ejemplos de usuarios v√°lidos seg√∫n personas]
- Transaction data: [Ejemplos de transacciones/operaciones v√°lidas]
- [Otros datos seg√∫n el dominio]

**Invalid Data Sets:**

- [Ejemplos de datos inv√°lidos que debemos probar]
- [Casos de input malicioso - SQL injection, XSS, etc.]

**Boundary Data Sets:**

- Min/Max values: [Seg√∫n validaciones del SRS]
- Empty/null values
- Special characters
- Unicode characters (si aplica internacionalizaci√≥n)

**Test Data Management:**

- ‚úÖ Use Faker.js for generating realistic test data
- ‚úÖ Create data factories for common entities
- ‚ùå NO hardcodear datos est√°ticos en tests
- ‚úÖ Clean up test data after test execution

---

### Test Environments

**Staging Environment:**

- URL: [Staging URL]
- Database: [Staging DB]
- External Services: [Mocked | Real staging versions]
- **Purpose:** Primary testing environment

**Production Environment:**

- URL: [Production URL]
- **Purpose:** ONLY smoke tests post-deployment
- **Restrictions:** NO destructive tests, NO test data creation

---

## ‚úÖ Entry/Exit Criteria

### Entry Criteria (Per Story)

Testing can start when:

- [ ] Story is fully implemented and deployed to staging
- [ ] Code review is approved by 2+ reviewers
- [ ] Unit tests exist and are passing (>80% coverage)
- [ ] Dev has done smoke testing and confirms basic functionality works
- [ ] No blocker bugs exist in dependent stories
- [ ] Test data is prepared and available in staging
- [ ] API documentation is updated (if API changes)

### Exit Criteria (Per Story)

Story is considered "Done" from QA perspective when:

- [ ] All test cases are executed
- [ ] Critical/High priority test cases: 100% passing
- [ ] Medium/Low priority test cases: ‚â•95% passing
- [ ] All critical and high bugs are resolved and verified
- [ ] Medium bugs have mitigation plan or are scheduled
- [ ] Regression testing passed (if changes affect other features)
- [ ] Non-functional requirements validated (performance, security)
- [ ] Test execution report is generated and shared
- [ ] Known issues are documented in release notes

### Epic Exit Criteria

Epic is considered "Done" from QA perspective when:

- [ ] ALL stories meet individual exit criteria
- [ ] Integration testing across all stories is complete
- [ ] E2E testing of critical user journeys is complete and passing
- [ ] API contract testing is complete (all endpoints validated)
- [ ] Non-functional testing is complete (NFRs from SRS validated)
- [ ] Exploratory testing session completed (findings documented)
- [ ] No critical or high bugs open
- [ ] QA sign-off document is created and approved

---

## üìù Non-Functional Requirements Validation

[Basado en .context/SRS/non-functional-specs.md, identificar NFRs que aplican a esta √©pica]

### Performance Requirements

**NFR-P-XXX:** [Descripci√≥n del NFR de performance]

- **Target:** [M√©trica espec√≠fica - ej: "Page load < 2s"]
- **Test Approach:** [C√≥mo lo vamos a validar]
- **Tools:** [Lighthouse, WebPageTest, etc.]

### Security Requirements

**NFR-S-XXX:** [Descripci√≥n del NFR de seguridad]

- **Requirement:** [Requerimiento espec√≠fico - ej: "All passwords hashed with bcrypt"]
- **Test Approach:** [C√≥mo lo vamos a validar]
- **Tools:** [OWASP ZAP, manual testing, etc.]

### Usability Requirements

**NFR-U-XXX:** [Descripci√≥n del NFR de usabilidad]

- **Requirement:** [Requerimiento espec√≠fico]
- **Test Approach:** [C√≥mo lo vamos a validar]

---

## üîÑ Regression Testing Strategy

**Regression Scope:**
[Identificar qu√© √°reas del sistema existente pueden verse afectadas por esta √©pica]

- [ ] Feature A: [C√≥mo puede afectarse]
- [ ] Feature B: [C√≥mo puede afectarse]

**Regression Test Execution:**

- Run automated regression suite before starting epic testing
- Re-run after all stories are complete
- Focus on integration points identified in architecture analysis

---

## üìÖ Testing Timeline Estimate

**Estimated Duration:** [X sprints | Y weeks]

**Breakdown:**

- Test case design: [X days]
- Test data preparation: [Y days]
- Test execution (per story): [Z days per story]
- Regression testing: [W days]
- Bug fixing cycles: [V days - buffer]
- Exploratory testing: [U days]

**Dependencies:**

- Depends on: [√âpicas que deben completarse primero]
- Blocks: [√âpicas que dependen de esta]

---

## üõ†Ô∏è Tools & Infrastructure

**Testing Tools:**

- E2E Testing: Playwright
- API Testing: Postman/Newman or Playwright API
- Unit Testing: Vitest (frontend), Jest (backend)
- Performance Testing: Lighthouse, WebPageTest
- Security Testing: OWASP ZAP (if applicable)
- Test Data: Faker.js

**CI/CD Integration:**

- [ ] Tests run automatically on PR creation
- [ ] Tests run on merge to main branch
- [ ] Tests run on deployment to staging
- [ ] Smoke tests run on deployment to production

**Test Management:**

- Jira Xray (test cases linked to stories)
- Test execution reports in Xray
- Bug tracking in Jira

---

## üìä Metrics & Reporting

**Test Metrics to Track:**

- Test cases executed vs. total
- Test pass rate
- Bug detection rate
- Bug fix rate
- Test coverage (code coverage from unit tests)
- Time to test (per story)

**Reporting Cadence:**

- Daily: Test execution status
- Per Story: Test completion report
- Per Epic: Comprehensive QA sign-off report

---

## üéì Notes & Assumptions

**Assumptions:**

- [Listar assumptions que se est√°n haciendo para este plan]

**Constraints:**

- [Listar constraints - tiempo, recursos, herramientas, etc.]

**Known Limitations:**

- [Qu√© NO se puede testear o validar completamente]

**Exploratory Testing Sessions:**

- Recommended: [X] exploratory testing sessions BEFORE implementation
  - Session 1: [Objetivo - ej: Test with mockups/prototypes]
  - Session 2: [Objetivo - ej: Test edge cases not covered in stories]

---

## üìé Related Documentation

- **Epic:** `.context/PBI/epics/EPIC-{PROYECTO}-{NUM}-{nombre}/epic.md`
- **Stories:** `.context/PBI/epics/EPIC-{PROYECTO}-{NUM}-{nombre}/stories/STORY-*/story.md`
- **Business Model:** `.context/idea/business-model.md`
- **PRD:** `.context/PRD/` (all files)
- **SRS:** `.context/SRS/` (all files)
- **Architecture:** `.context/SRS/architecture-specs.md`
- **API Contracts:** `.context/SRS/api-contracts.yaml`

---

**Formato:** Markdown estructurado, listo para copiar a `.context/PBI/epics/EPIC-{PROYECTO}-{NUM}-{nombre}/feature-test-plan.md`

**Prerequisitos:**

- TODOS los archivos de contexto (idea, PRD, SRS) deben estar completos
- Epic.md y todos los story.md de la √©pica deben existir
- Tiempo para analizar cr√≠ticamente y no solo generar checklist

**Post-generaci√≥n:**

- Compartir "Critical Analysis & Questions" con PO/Dev ANTES de que empiecen implementaci√≥n
- Revisar feedback y ajustar stories si es necesario
- Crear test cases en Jira Xray y linkear con stories

**Versi√≥n:** 2.0 - Shift-Left with Complete Context & Critical Analysis
**√öltima actualizaci√≥n:** 2025-11-04
